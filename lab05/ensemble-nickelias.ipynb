{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Lab\n",
    "### Nick Elias\n",
    "### Date: 4/11/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# ------------------------------------------------\n",
    "# Imports once at the top, organized\n",
    "# ------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "# The dataset includes 11 physicochemical input variables (features):\n",
    "# ---------------------------------------------------------------\n",
    "# - fixed acidity          mostly tartaric acid\n",
    "# - volatile acidity       mostly acetic acid (vinegar)\n",
    "# - citric acid            can add freshness and flavor\n",
    "# - residual sugar         remaining sugar after fermentation\n",
    "# - chlorides              salt content\n",
    "# - free sulfur dioxide    protects wine from microbes\n",
    "# - total sulfur dioxide   sum of free and bound forms\n",
    "# - density                related to sugar content\n",
    "# - pH                     acidity level (lower = more acidic)\n",
    "# - sulphates              antioxidant and microbial stabilizer\n",
    "# - alcohol                % alcohol by volume\n",
    "\n",
    "# The target variable is:\n",
    "# - quality (integer score from 0 to 10, rated by wine tasters)\n",
    "\n",
    "# We will simplify this target into three categories:\n",
    "#   - low (3–4), medium (5–6), high (7–8) to make classification feasible.\n",
    "#   - we will also make this numeric (we want both for clarity)\n",
    "# The dataset contains 1599 samples and 12 columns (11 features + target).\n",
    "\n",
    "\n",
    "\n",
    "# Load spiral dataset\n",
    "spiral = pd.read_csv(\"spiral.csv\")\n",
    "\n",
    "# Display basic information\n",
    "spiral.info()\n",
    "\n",
    "# Display first few rows\n",
    "print(spiral.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Prepare the Data\n",
    "Includes cleaning, feature engineering, encoding, splitting, helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function that:\n",
    "\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "\n",
    "# Explain what we do and why as you proceed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target\n",
    "\n",
    "\n",
    "# Explain / introduce your choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.  Evaluate Model Performance (Choose 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest (100)\t\n",
    "   1. A strong baseline model using 100 decision trees.\n",
    "2. Random Forest (200, max_depth=10)\t\n",
    "   1. Adds more trees, but limits tree depth to reduce overfitting.\n",
    "3. AdaBoost (100)\t\n",
    "   1. Boosting method that focuses on correcting previous errors.\n",
    "4. AdaBoost (200, lr=0.5)\t\n",
    "    More iterations and slower learning for better generalization.\n",
    "5.\tGradient Boosting (100)\t\n",
    "    Boosting approach using gradient descent.\n",
    "6.\tVoting (DT + SVM + NN)\t\n",
    "    Combines diverse models by averaging their predictions.\n",
    "7.\tVoting (RF + LR + KNN)\t\n",
    "    Another mix of different model types.\n",
    "8.\tBagging (DT, 100)\tBuilds many trees in parallel on different samples.\n",
    "9.\tMLP Classifier\tA basic neural network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a helper function that might be nice -\n",
    "#  feel free to use or adjust as you like. \n",
    "\n",
    "\n",
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "######################################\n",
    "#Here's how to create the different types of \n",
    "# ensemble models listed above \n",
    "# (you don't need to do all of them yourself. \n",
    "# Choose 2 - we have a whole team working on this.)\n",
    "######################################\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. Random Forest (200, max depth=10) \n",
    "evaluate_model(\n",
    "    \"Random Forest (200, max_depth=10)\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 3. AdaBoost \n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 4. AdaBoost (200, lr=0.5) \n",
    "evaluate_model(\n",
    "    \"AdaBoost (200, lr=0.5)\",\n",
    "    AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 6. Voting Classifier (DT, SVM, NN) \n",
    "voting1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"DT\", DecisionTreeClassifier()),\n",
    "        (\"SVM\", SVC(probability=True)),\n",
    "        (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 7. Voting Classifier (RF, LR, KNN) \n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 8. Bagging \n",
    "evaluate_model(\n",
    "    \"Bagging (DT, 100)\",\n",
    "    BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 9. MLP Classifier \n",
    "evaluate_model(\n",
    "    \"MLP Classifier\",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Compare Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df)\n",
    "\n",
    "######################################\n",
    "# Recommendation: See if you can add gap calculations \n",
    "# to your results and sort the table by test accuracy \n",
    "# to find the best models more efficiently. \n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7. Conclusions and Insights\n",
    "\n",
    "Using both your results and the results from others, which options are performing well and why do you think so. \n",
    "\n",
    "This is your value as an analyst - narrate your story, link to other notebooks, provide a comprehensive view of what you feel is the best model for predicting quality in red wine. Base all your reasoning on data. Feel free to tune parameters if you like.  Discuss the types of models and why you think some seem to be more helpful. List the next steps you'd like to try if you were in a competition to build the best predictor. \n",
    "\n",
    "Don't just copy code and don't just copy AI insights - use them to learn, but we all get them for free. Use all your tools to provide your own unique value and insights. Professional communication skills are critical. Evaluate your work in the context of others - how well can you craft a unique data story and present a compelling project to your clients / readers / self. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
